---
title: ""
subtitle: ""
author: ""
institute: ""
date: ""
output:
  xaringan::moon_reader:
    css: [default, zh-CN.css, Custumed_Style.css]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---
class: center, middle
<span style="font-size: 60px;">第五章</span> <br>
<span style="font-size: 50px;">如何清理数据 二 数据的预处理</span> <br>

<span style="font-size: 30px;">How to use dplyr</span> <br>
<span style="font-size: 30px;">胡传鹏</span> <br>
<span style="font-size: 30px;">PPT: yuki</span> <br>
<span style="font-size: 30px;">2023/02/22</span> <br>

---
# 5.1 数据预处理准备
## 载入包
```{r used pacakge}
# 所有路径使用相对路径
library(here)
# 包含了dplyr和%>%等好用的包的集合
library(tidyverse)
```

---
# 5.1 数据预处理准备
## 设置工作路径
```{r Set Working Directory}
# 养成用相对路径的好习惯，便于其他人运行你的代码
WD <-  here::here()
getwd()
```

---
# 5.1 数据预处理准备
## 读取原始数据 
### Penguin
```{r Read Penguin RawData}
# 读取原始数据
df.pg.raw <-  read.csv('../DATA/penguin_rawdata.csv',
                       header = T, sep=",", stringsAsFactors = FALSE)
# 这里查看表格使用的是DT::datatable，为了PPT里好看
# 你可以直接点R Studio右边的环境变量来看，或者用str()或者head()
```
```{r Read Penguin RawData DT, echo=FALSE}
DT::datatable(head(df.pg.raw, 10),
              fillContainer = TRUE, options = list(pageLength = 3))
```

---
# 5.1 数据预处理准备
## 读取原始数据
### Match Task
```{r Read Match Task RawData}
# 读取原始数据
df.mt.raw <-  read.csv('../DATA/MS_rep_matchingTask_raw.csv',
                       header = T, sep=",", stringsAsFactors = FALSE) 
```
```{r Read Match Task RawData DT, echo=FALSE}
DT::datatable(head(df.mt.raw, 10),
              fillContainer = TRUE, options = list(pageLength = 3))
```

---
# 5.2 数据预处理的基本操作
## dplyr
<br>

dplyr is a grammar of data manipulation, providing a consistent set of verbs that help you solve the most common data manipulation challenges: <br>

<br>

<img src="https://dplyr.tidyverse.org/logo.png" alt="dplyr" style="display: block; margin: 0 auto;">
---
# 5.2 数据预处理的基本操作
## dplyr::functions
- filter() 选择符合某个条件的行（可能代表被试） <br>

- mutate() 生成新的变量 <br>

- group_by() 依据某些变量产生的条件，给数据分组 <br>
  **如果你使用了 "group_by",** <br>
  **一定要在summarise后使用 "ungroup".** <br>
  
- summarise() 进行某些加减乘除的运算 <br>  

- ungroup() 取消刚刚进行的分组 <br>  

- select() 选择最终进行分析时需要用到的变量，同时也起到了为所有变量排序的功能 <br>

- arrange() 某一列的值，按照某个顺序排列（其他列也会随之变动） <br>

_当你清洗数据时，也基本上会按照这个顺序来使用_
  
---
class: center, middle
# 接下来就要正式讲dplyr了
## 准备好了吗
<img src="https://dplyr.tidyverse.org/logo.png" alt="dplyr" style="display: block; margin: 0 auto;">
<br>
_我会在标题中写出这个过程对应的SPSS名称_

---
# 5.2 数据预处理的基本操作
## dplyr::filter 
### 选择个案 
```{r example of filter rawdata_penguin}
# 使用filter筛选出数据集中1995之后出生的被试
df.clean.filter <- df.pg.raw %>%
  dplyr::filter(.,age >= 1995)
```
```{r example of filter rawdata_penguin DT, echo=FALSE}
# 看看筛选后的数据是不是只有95后
DT::datatable(head(df.clean.filter, 10),
              fillContainer = TRUE, options = list(pageLength = 3))
```

---
# 5.2 数据预处理的基本操作
## dplyr::select
### 选择变量
```{r example of select rawdata_penguin}
# 使用select选择age和ALEX的所有题目
df.clean.select <- df.pg.raw %>%
  dplyr::select(age, starts_with("ALEX"), eatdrink, avoidance)
#笨一点的方法，就是把16个ALEX都写出来
```
```{r example of select rawdata_penguin DT, echo=FALSE}
# 看看其他变量是不是都消失了
DT::datatable(head(df.clean.select, 10),
              fillContainer = TRUE, options = list(pageLength = 3))
```

---
# 5.2 数据预处理的基本操作
## dplyr::mutate 
### 计算变量 方法1
```{r example of mutate_1 rawdata_penguin}
# 把ALEX1 - 4求和
df.clean.mutate_1 <- df.pg.raw %>% 
  dplyr::mutate(ALEX_SUM = ALEX1 + ALEX2 + ALEX3 + ALEX4)
```
```{r example of mutate_1 rawdata_penguin DT, echo=FALSE}
# 看看是不是真的求和了
DT::datatable(head(df.clean.mutate_1, 10),
              fillContainer = TRUE, options = list(pageLength = 3))
```

---
# 5.2 数据预处理的基本操作
## dplyr::mutate 
### 计算变量 方法2 ~~chatGPT告诉我的~~
```{r example of mutate_2 rawdata_penguin}
# 这个函数怎么运行的不重要，以后你只需要把ALEX改成你的文件里的变量名
df.clean.mutate_2 <- df.pg.raw %>% 
  dplyr::mutate(ALEX_SUM = rowSums(select(., starts_with("ALEX"))))
```
```{r example of mutate_2 rawdata_penguin DT, echo=FALSE}
DT::datatable(head(df.clean.mutate_2, 10),
              fillContainer = TRUE, options = list(pageLength = 3))
```

---
# 5.2 数据预处理的基本操作
## dplyr::mutate 
### 重新编码为不同变量
```{r example of mutate_3 rawdata_penguin}
df.clean.mutate_3 <- df.pg.raw %>% 
  dplyr::mutate(decade = case_when(age <= 1969 ~ 60,
                                   age >= 1970 & age <= 1979 ~ 70,
                                   age >= 1980 & age <= 1989 ~ 80,
                                   age >= 1990 & age <= 1999 ~ 90)
                ) #当括号多的时候注意括号的位置
```
```{r example of mutate_3 rawdata_penguin DT, echo=FALSE}
DT::datatable(head(df.clean.mutate_3, 10),
              fillContainer = TRUE, options = list(pageLength = 3))
```

---
# 5.2 数据预处理的基本操作
## dplyr::group_by & summarise
### 拆分文件 分组计算
```{r example of group_by rawdata_penguin}
df.clean.group_by <- df.clean.mutate_3 %>%
  dplyr::group_by(.,decade) %>% # 根据eatdrink这个变量拆分文件，eatdrink包含几个水平，文件就会被拆分为几份
  dplyr::summarise(mean_avoidance = mean(avoidance)) %>% # 计算eatdrink每个水平下，age=1999的有多少个
  dplyr::ungroup()
```
```{r example of group_by rawdata_penguin DT, echo=FALSE}
# 拆分文件并不会让源文件产生任何视觉上的变化
DT::datatable(head(df.clean.group_by, 4),
              fillContainer = TRUE, options = list(pageLength = 4))
```

---
# 5.2 数据预处理的基本操作
## dplyr::functions
### 把之前学到的函数一起使用
```{r example of total rawdata_penguin}
df.pg.clean <- df.pg.raw %>%
  dplyr::filter(eatdrink == 1) %>% 
  # 选择eatdrink为1的被试
  dplyr::select(age, starts_with("ALEX"), eatdrink, avoidance) %>%
  # 选择四个变量，分别是age，ALEX，eatdrink和avoidance
  dplyr::mutate(ALEX_SUM = rowSums(select(., starts_with("ALEX"))),
                # 把所有ALEX的题目分数求和
                decade = case_when(age <= 1969 ~ 60,
                                   age >= 1970 & age <= 1979 ~ 70,
                                   age >= 1980 & age <= 1989 ~ 80,
                                   age >= 1990 & age <= 1999 ~ 90)
                # 把年龄按照年代来重新编码
                ) %>%
  dplyr::group_by(decade) %>%
  # 按照年代将数据拆分
  dplyr::summarise(mean_ALEX = mean(ALEX_SUM)) %>%
  # 计算每个年代的被试的平均的ALEX_SUM
  dplyr::ungroup()
  # 解除对数据的拆分
```

---
# 5.2 数据预处理的基本操作
## dplyr::functions
### 把之前学到的函数一起使用
```{r result of total, echo=FALSE}
DT::datatable(head(df.pg.clean, 5),
              fillContainer = TRUE, options = list(pageLength = 5))
```

---
# 5.3 数据预处理的进阶操作
## tidyr
**The goal of tidyr is to help you create tidy data. Tidy data is data where:** <br>

- Every column is variable. <br>
- Every row is an observation. <br>
- Every cell is a single value. <br>

<img src="https://tidyr.tidyverse.org/logo.png" alt="dplyr" style="display: block; margin: 0 auto;">
---
# 5.3 数据预处理的进阶操作
## tidyr::functions
- separate() 把一个变量的单元格内的字符串拆成两份，变成两个变量 <br>
  **更适合用于按固定分隔符分割字符串，如将“2022-02-25”分成“2022”、“02”和“25”三列** <br>
- extract() 类似于separate <br>
  **更适合用于从字符串中提取特定的信息，如将“John Smith”分成“John”和“Smith”两列** <br>
- unite() 把多个列（字符串）整合为一列 <br>

- pivot_longer() 把宽数据转化为长数据 <br>
- pivot_wider() 把长数据转化为宽数据 <br>   
  
- drop_na() 删除缺失值
---
class: center, middle
# 接下来就要正式讲tidyr了
## 准备好了吗
<img src="https://tidyr.tidyverse.org/logo.png" alt="dplyr" style="display: block; margin: 0 auto;">
<br>
_我很少能在SPSS实现这些功能，或者说很难实现_
---
# 5.3 数据预处理的进阶操作
## tidyr::separate
### 拆分单元格内字符串
```{r tidyr::separate | rawdata_matchtask}
df.clean.separate <- df.mt.raw %>%
  tidyr::separate(., col = Shape, into = c("Shape_moral", "Shape_self"), 
                                  sep = "(?<=moral|immoral)(?=Self|Other)") %>%
  tidyr::separate(., col = Label, into = c("Label_moral", "Label_self"), 
                                  sep = "(?<=moral|immoral)(?=Self|Other)") %>%
  dplyr::select(Subject, Shape_moral, Shape_self, Label_moral, Label_self, everything())
```
```{r tidyr::separate | rawdata_matchtask DT, echo=FALSE}
DT::datatable(head(df.clean.separate, 10),
              fillContainer = TRUE, options = list(pageLength = 3))
```
---
# 5.3 数据预处理的进阶操作
## tidyr::extract
### 拆分单元格内字符串
```{r tidyr::extract | rawdata_matchtask}
df.clean.extract <- df.mt.raw %>% 
  tidyr::extract(Shape, into = c("Shape_moral", "Shape_self"),
                        regex = "(moral|immoral)(Self|Other)", remove = FALSE) %>% 
  tidyr::extract(Label, into = c("Label_moral", "Label_self"), 
                        regex = "(moral|immoral)(Self|Other)", remove = FALSE) %>% 
  dplyr::select(Subject, Shape_moral, Shape_self, Label_moral, Label_self, everything())
```
```{r tidyr::extract | rawdata_matchtask DT, echo=FALSE}
DT::datatable(head(df.clean.extract, 10),
              fillContainer = TRUE, options = list(pageLength = 3))
```

---
# 5.3 数据预处理的进阶操作
## tidyr::unite
### 合并单元格的字符串
```{r tidyr::unite | rawdata_matchtask}
df.clean.unite <- df.clean.separate %>%
  tidyr::unite(Shape, Shape_moral, Shape_self, sep = "") %>%
  tidyr::unite(Label, Label_moral, Label_self, sep = "") 
```
```{r tidyr::unite | rawdata_matchtask DT, echo=FALSE}
DT::datatable(head(df.clean.unite, 10),
              fillContainer = TRUE, options = list(pageLength = 3))
```

---
# 5.3 数据预处理的进阶操作
## tidyr::pivot_wider
### 长数据与宽数据的相互转换
```{r pivot_wider | rawdata_matchtask, warning=FALSE}
df.clean.wide <- df.mt.raw %>% 
  dplyr::select(Subject, Block, Bin, Trial, RT) %>%
  tidyr::pivot_wider(names_from = "Trial", values_from = "RT")
```
```{r pivot_wider | rawdata_matchtask DT, echo=FALSE}
DT::datatable(head(df.clean.wide, 10),
              fillContainer = TRUE, options = list(pageLength = 3))
```

---
# 5.3 数据预处理的进阶操作
## tidyr::pivot_longer
### 长数据与宽数据的相互转换
```{r pivot_longer | rawdata_matchtask}
df.clean.long <- df.clean.wide %>% 
  tidyr::pivot_longer(cols = 4:27,
                      names_to = "Trial",
                      values_to = "RT") 
```
```{r pivot_longer | rawdata_matchtask DT, echo=FALSE}
DT::datatable(head(df.clean.long, 48),
              fillContainer = TRUE, options = list(pageLength = 3))
```

---
# 5.3 数据预处理的进阶操作
## tidyr::drop_na
### 删除含有缺失值的行（被试，试次...）
```{r drop_na | rawdata_matchtask, warning=FALSE}
df.drou_na <- df.mt.raw %>% 
  tidyr::drop_na()
```
```{r drop_na | rawdata_matchtask DT, echo=FALSE}
DT::datatable(head(df.drou_na, 10),
              fillContainer = TRUE, options = list(pageLength = 3))
```





























